{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing required Dependencies"
      ],
      "metadata": {
        "id": "NqlUkiTwRM7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "07z6sXHdDwhZ",
        "outputId": "f9f79f28-73d8-4c80-b5e7-bcabb0bf6d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.1.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3,>=0.2 (from langgraph)\n",
            "  Downloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.5 (from langchain_community)\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.1)\n",
            "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.5->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (2.7.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2->langgraph)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.26.0->langchain_openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langgraph, langchain-text-splitters, langchain_openai, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.9 langchain-text-splitters-0.2.1 langchain_community-0.2.5 langchain_openai-0.1.9 langgraph-0.1.1 langsmith-0.1.81 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.35.3 orjson-3.10.5 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langgraph langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up Required Environment Variables"
      ],
      "metadata": {
        "id": "PlLZh9VORbXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "os.environ['LANGCHAIN_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "H3LQQXquM7rn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the OpenAI model GPT-4 using Langchain"
      ],
      "metadata": {
        "id": "8IGQTHlwRe8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "4gVsvmJ4M-al"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SQL Query Generation and Optimization </h1>"
      ],
      "metadata": {
        "id": "q-dsoipOcsLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Input File"
      ],
      "metadata": {
        "id": "ss-zbNwtnwlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        questions = file.readlines()\n",
        "    return [question.strip() for question in questions if question.strip()]"
      ],
      "metadata": {
        "id": "7u_OMjNAm92m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL Query Generation"
      ],
      "metadata": {
        "id": "KMC3b3SBpGqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql_query(question):\n",
        "    prompt = f\"Convert the following natural language question into an SQL query:\\nQuestion: {question}\\nSQL Query:\"\n",
        "    sql_query=model.invoke(input=prompt)\n",
        "    return sql_query.content"
      ],
      "metadata": {
        "id": "AQthArAvnySs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Optimization"
      ],
      "metadata": {
        "id": "q4ALfvoQIqL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_sql_query(sql_query):\n",
        "    prompt = f\"Analyze the following SQL query and suggest optimizations to improve performance:\\nSQL Query: {sql_query}\\nOptimizations:\"\n",
        "    optimizations=model.invoke(input=prompt)\n",
        "\n",
        "    return optimizations.content"
      ],
      "metadata": {
        "id": "LhnxegG6n3vj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well-formatted Output"
      ],
      "metadata": {
        "id": "bZWhqJ5XIx57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = read_input('questions.txt')\n",
        "for i, question in enumerate(questions, 1):\n",
        "    sql_query = generate_sql_query(question)\n",
        "    optimizations = optimize_sql_query(sql_query)\n",
        "    print(f\"Question {i}: {question}\\n\")\n",
        "    print(\"Generated SQL Query:\\n\")\n",
        "    print(sql_query + \"\\n\")\n",
        "    print(\"Optimization Suggestions:\\n\")\n",
        "    print(optimizations + \"\\n\")\n",
        "    print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Ty-U6AHTHW",
        "outputId": "d5fbeed6-58d0-4456-9ee9-40ec5926f584"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Show me the top 5 highest-paid employees.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT * \n",
            "FROM employees\n",
            "ORDER BY salary DESC\n",
            "LIMIT 5;\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "To optimize the performance of this SQL query, you can consider the following suggestions:\n",
            "\n",
            "1. Use Indexing: Creating an index on the 'salary' column can improve the performance of the ORDER BY clause. This will allow the database to quickly retrieve and sort the data based on the 'salary' column.\n",
            "\n",
            "2. Limit the Columns Selected: Instead of using SELECT *, explicitly list only the columns needed in the query. This can reduce the amount of data that needs to be retrieved and processed, improving performance.\n",
            "\n",
            "3. Use Caching: If the query is frequently executed with the same parameters, consider caching the results to avoid redundant queries.\n",
            "\n",
            "4. Partitioning: If the 'employees' table is large, consider partitioning it based on the 'salary' column. This can help distribute the data across multiple partitions, improving query performance.\n",
            "\n",
            "5. Use Materialized Views: If the query is complex and involves multiple tables, consider using materialized views to precompute and store the results. This can improve query performance for frequently executed queries.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Question 2: Who is the youngest employee in the Engineering department?\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT name\n",
            "FROM employees\n",
            "WHERE department = 'Engineering'\n",
            "ORDER BY age ASC\n",
            "LIMIT 1;\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "1. Indexing: Create an index on the 'department' column as well as the 'age' column in the 'employees' table to make the WHERE clause and ORDER BY clause more efficient.\n",
            "\n",
            "2. Use a covering index: Create a covering index that includes both the 'department' and 'age' columns so that the query can be satisfied using only the index without having to access the actual table data.\n",
            "\n",
            "3. Use a composite index: Create a composite index on both the 'department' and 'age' columns to further optimize the query.\n",
            "\n",
            "4. Reconsider the LIMIT clause: If the query is frequently fetching the first employee in the 'Engineering' department, consider if you really need the LIMIT clause. Removing it could improve performance.\n",
            "\n",
            "5. Monitor query performance: Use tools like EXPLAIN to analyze the query execution plan and identify any potential bottlenecks. Make adjustments based on the findings to improve performance.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Question 3: Find all employees who were hired in the year 2019.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT * \n",
            "FROM employees\n",
            "WHERE YEAR(hire_date) = 2019;\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "1. Use an index on the hire_date column: By creating an index on the hire_date column, the database engine can quickly locate the rows that meet the condition in the WHERE clause, resulting in improved performance.\n",
            "\n",
            "2. Avoid using functions in the WHERE clause: Instead of using the YEAR function in the WHERE clause, consider storing the year separately in a column or using a range query to filter the results based on hire_date >= '2019-01-01' AND hire_date < '2020-01-01'. This can eliminate the need to apply a function to every row in the table.\n",
            "\n",
            "3. Limit the columns selected: Instead of using \"SELECT *\", specify only the columns that are needed in the result set. This can reduce the amount of data that needs to be retrieved and can improve query performance.\n",
            "\n",
            "4. Consider partitioning the table: If the employees table is very large, partitioning can help distribute the data across multiple physical storage units, making it easier for the database engine to retrieve the relevant rows based on the condition in the WHERE clause.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Question 4: Show the names of employees whose salary is above the average salary in their department.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT name\n",
            "FROM employees\n",
            "WHERE salary > (SELECT AVG(salary) \n",
            "                FROM employees \n",
            "                GROUP BY department \n",
            "                HAVING department = employees.department);\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "1. Use a join instead of a subquery:\n",
            "Instead of using a subquery to calculate the average salary by department, you can use a join to get the average salary for each department and then compare it with the salary of each employee. This can reduce the number of calculations and improve performance.\n",
            "\n",
            "2. Create an index on the salary column:\n",
            "Creating an index on the salary column can help speed up the retrieval of data when filtering based on the salary column. This can improve the performance of the query significantly.\n",
            "\n",
            "3. Use EXISTS instead of IN:\n",
            "Using EXISTS instead of IN can sometimes improve performance, especially when dealing with large datasets. Consider rewriting the query to use EXISTS to check for the existence of records in the subquery instead of using IN.\n",
            "\n",
            "4. Consider denormalizing the data:\n",
            "If performance is a critical issue and the query is run frequently, you may consider denormalizing the data by storing the average salary by department in a separate table. This can eliminate the need to calculate the average salary each time the query is run, improving performance.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Question 5: Display the names of employees whose first and last names start with the same letter.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT name \n",
            "FROM employees \n",
            "WHERE SUBSTRING_INDEX(first_name, ' ', 1) LIKE CONCAT(SUBSTRING_INDEX(last_name, ' ', 1), '%')\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "1. Indexes: Ensure that there are indexes on the 'first_name' and 'last_name' columns to improve the performance of the query. Indexes can speed up the search process and make the query run faster.\n",
            "\n",
            "2. Use a more efficient comparison: Instead of using the LIKE operator with CONCAT and SUBSTRING_INDEX functions, consider using a different comparison method that is more efficient. For example, you could use the equality operator (=) with a comparison of the first word of the first name and last name directly.\n",
            "\n",
            "3. Normalize the data: If possible, consider normalizing the data in the 'first_name' and 'last_name' columns so that the comparison can be done more efficiently without the need for string manipulation functions.\n",
            "\n",
            "4. Use full-text search: If the goal of the query is to find similar names, consider using a full-text search feature provided by the database management system. Full-text search can be more efficient for searching text data than string manipulation functions.\n",
            "\n",
            "5. Limit the result set: If the query is returning a large number of records, consider adding a LIMIT clause to limit the number of results returned. This can help improve query performance by reducing the amount of data that needs to be processed.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Question 6: Find the employee with the highest salary in each department\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT department, MAX(salary) AS highest_salary\n",
            "FROM employees\n",
            "GROUP BY department;\n",
            "\n",
            "Optimization Suggestions:\n",
            "\n",
            "1. Indexes: Make sure that there is an index on the 'department' column in the 'employees' table. This will help speed up the grouping process.\n",
            "2. Partitioning: If the 'employees' table is large, consider partitioning it by the 'department' column. This can help improve query performance by only scanning the relevant partitions.\n",
            "3. Caching: Consider caching the result of this query if the data does not change frequently. This can help reduce the overhead of running the query multiple times.\n",
            "4. Avoid unnecessary columns: If the 'department' column is the only one needed in the result set, remove the 'salary' column from the SELECT statement to reduce unnecessary data retrieval.\n",
            "5. Use appropriate data types: Make sure that the 'department' column is using an appropriate data type and size to avoid any unnecessary overhead.\n",
            "6. Consider denormalization: If performance is still an issue, consider denormalizing the data by storing the highest salary for each department in a separate table. This can help improve query performance by reducing the need for aggregation functions like MAX().\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extra Credit 1</h2>"
      ],
      "metadata": {
        "id": "bTTBTpdOI00e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For complex queries, the LLM's capability can handle subqueries and joins, but may require more context. Hence modifying our sql query generation function for this."
      ],
      "metadata": {
        "id": "-7L9hpJIKjRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_complex_sql_query(question):\n",
        "    prompt = f\"Convert the following complex natural language question into an SQL query. Handle subqueries and joins appropriately:\\nQuestion: {question}\\nComplex SQL Query:\"\n",
        "    sql_query = model.invoke(prompt.content)\n",
        "    return sql_query"
      ],
      "metadata": {
        "id": "mOcvwsPsINOL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extra Credit 2</h2>"
      ],
      "metadata": {
        "id": "2juIyE4GKsTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table schema and the data to be inserted."
      ],
      "metadata": {
        "id": "hPp-kzitPSCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Define the table schema\n",
        "create_table_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS employees (\n",
        "    EmployeeID INTEGER PRIMARY KEY,\n",
        "    FirstName TEXT NOT NULL,\n",
        "    LastName TEXT NOT NULL,\n",
        "    Age INTEGER,\n",
        "    Department TEXT,\n",
        "    Position TEXT,\n",
        "    Salary REAL,\n",
        "    HireDate TEXT,\n",
        "    ManagerID INTEGER\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Define the data to be inserted\n",
        "employee_data = [\n",
        "    (1, 'John', 'Smith', 28, 'Sales', 'Manager', 85000, '01/03/2015', 21),\n",
        "    (2, 'Jane', 'Doe', 34, 'Engineering', 'Developer', 95000, '23/05/2016', 6),\n",
        "    (3, 'Emily', 'Johnson', 29, 'HR', 'Generalist', 70000, '14/08/2017', 7),\n",
        "    (4, 'Michael', 'Brown', 45, 'Marketing', 'Coordinator', 80000, '11/11/2014', 20),\n",
        "    (5, 'Sarah', 'Williams', 31, 'Sales', 'Consultant', 85000, '25/07/2013', 1),\n",
        "    (6, 'David', 'Jones', 38, 'Engineering', 'Manager', 95000, '17/09/2019', 1),\n",
        "    (7, 'Laura', 'Garcia', 26, 'HR', 'Manager', 70000, '02/12/2018', 21),\n",
        "    (8, 'James', 'Miller', 39, 'Marketing', 'SEO', 80000, '10/01/2020', 20),\n",
        "    (9, 'Anna', 'Davis', 27, 'Sales', 'Associate', 85000, '01/03/2015', 1),\n",
        "    (10, 'Robert', 'Rodriguez', 41, 'Engineering', 'QA', 95000, '23/05/2016', 6),\n",
        "    (11, 'Linda', 'Martinez', 33, 'HR', 'Coordinator', 70000, '14/08/2017', 7),\n",
        "    (12, 'William', 'Hernandez', 30, 'Marketing', 'Analyst', 80000, '11/11/2014', 20),\n",
        "    (13, 'Elizabeth', 'Lopez', 36, 'Sales', 'Analyst', 85000, '25/07/2013', 1),\n",
        "    (14, 'Richard', 'Gonzalez', 42, 'Engineering', 'DevOps', 95000, '17/09/2019', 6),\n",
        "    (15, 'Jessica', 'Wilson', 32, 'HR', 'Analyst', 70000, '02/12/2018', 7),\n",
        "    (16, 'Joseph', 'Anderson', 37, 'Marketing', 'Associate', 80000, '10/01/2020', 20),\n",
        "    (17, 'Karen', 'Thomas', 29, 'Sales', 'Coordinator', 85000, '01/03/2015', 1),\n",
        "    (18, 'Thomas', 'Taylor', 35, 'Engineering', 'Technical support', 95000, '23/05/2016', 6),\n",
        "    (19, 'Nancy', 'Moore', 40, 'HR', 'Recruiter', 70000, '14/08/2017', 7),\n",
        "    (20, 'Charles', 'Jackson', 43, 'Marketing', 'Manager', 80000, '11/11/2014', 21),\n",
        "    (21, 'Alex', 'Johnson', 50, 'Management', 'CEO', 200000, '01/01/2010', 22)\n",
        "]\n"
      ],
      "metadata": {
        "id": "gRSHhUZ6Krjt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Script to create the table and insert the data.\n"
      ],
      "metadata": {
        "id": "YKf9B3IuPXrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_connection(db_file):\n",
        "    \"\"\" Create a database connection to the SQLite database \"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        print(f\"Connected to {db_file}\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "    return conn\n",
        "\n",
        "def create_table(conn):\n",
        "    \"\"\" Create a table from the create_table_sql statement \"\"\"\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(create_table_sql)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "def insert_data(conn):\n",
        "    \"\"\" Insert data into the employees table \"\"\"\n",
        "    insert_sql = \"\"\"\n",
        "    INSERT INTO employees (EmployeeID, FirstName, LastName, Age, Department, Position, Salary, HireDate, ManagerID)\n",
        "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.executemany(insert_sql, employee_data)\n",
        "        conn.commit()\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "def query_data(conn):\n",
        "    \"\"\" Query all rows in the employees table \"\"\"\n",
        "    select_sql = \"SELECT * FROM employees\"\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(select_sql)\n",
        "        rows = cursor.fetchall()\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "database = \"mydatabase.db\"\n",
        "conn = create_connection(database)\n",
        "if conn:\n",
        "    create_table(conn)\n",
        "    insert_data(conn)\n",
        "    query_data(conn)\n",
        "    conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh8UQLaaOAEx",
        "outputId": "3967213b-78fc-4dc1-99d4-9b5ba5045778"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to mydatabase.db\n",
            "(1, 'John', 'Smith', 28, 'Sales', 'Manager', 85000.0, '01/03/2015', 21)\n",
            "(2, 'Jane', 'Doe', 34, 'Engineering', 'Developer', 95000.0, '23/05/2016', 6)\n",
            "(3, 'Emily', 'Johnson', 29, 'HR', 'Generalist', 70000.0, '14/08/2017', 7)\n",
            "(4, 'Michael', 'Brown', 45, 'Marketing', 'Coordinator', 80000.0, '11/11/2014', 20)\n",
            "(5, 'Sarah', 'Williams', 31, 'Sales', 'Consultant', 85000.0, '25/07/2013', 1)\n",
            "(6, 'David', 'Jones', 38, 'Engineering', 'Manager', 95000.0, '17/09/2019', 1)\n",
            "(7, 'Laura', 'Garcia', 26, 'HR', 'Manager', 70000.0, '02/12/2018', 21)\n",
            "(8, 'James', 'Miller', 39, 'Marketing', 'SEO', 80000.0, '10/01/2020', 20)\n",
            "(9, 'Anna', 'Davis', 27, 'Sales', 'Associate', 85000.0, '01/03/2015', 1)\n",
            "(10, 'Robert', 'Rodriguez', 41, 'Engineering', 'QA', 95000.0, '23/05/2016', 6)\n",
            "(11, 'Linda', 'Martinez', 33, 'HR', 'Coordinator', 70000.0, '14/08/2017', 7)\n",
            "(12, 'William', 'Hernandez', 30, 'Marketing', 'Analyst', 80000.0, '11/11/2014', 20)\n",
            "(13, 'Elizabeth', 'Lopez', 36, 'Sales', 'Analyst', 85000.0, '25/07/2013', 1)\n",
            "(14, 'Richard', 'Gonzalez', 42, 'Engineering', 'DevOps', 95000.0, '17/09/2019', 6)\n",
            "(15, 'Jessica', 'Wilson', 32, 'HR', 'Analyst', 70000.0, '02/12/2018', 7)\n",
            "(16, 'Joseph', 'Anderson', 37, 'Marketing', 'Associate', 80000.0, '10/01/2020', 20)\n",
            "(17, 'Karen', 'Thomas', 29, 'Sales', 'Coordinator', 85000.0, '01/03/2015', 1)\n",
            "(18, 'Thomas', 'Taylor', 35, 'Engineering', 'Technical support', 95000.0, '23/05/2016', 6)\n",
            "(19, 'Nancy', 'Moore', 40, 'HR', 'Recruiter', 70000.0, '14/08/2017', 7)\n",
            "(20, 'Charles', 'Jackson', 43, 'Marketing', 'Manager', 80000.0, '11/11/2014', 21)\n",
            "(21, 'Alex', 'Johnson', 50, 'Management', 'CEO', 200000.0, '01/01/2010', 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing queries on database."
      ],
      "metadata": {
        "id": "O9RMKeZZPqbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_query(db_path, sql_query):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        results = cursor.fetchall()\n",
        "        return results\n",
        "    except sqlite3.Error as e:\n",
        "        return str(e)\n",
        "    finally:\n",
        "        conn.close()"
      ],
      "metadata": {
        "id": "4SK_ghWvPhmk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetching and displaying results from the database"
      ],
      "metadata": {
        "id": "kPayWVRhQnGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = read_input('questions.txt')\n",
        "for i, question in enumerate(questions, 1):\n",
        "    sql_query = generate_sql_query(question)\n",
        "    result= execute_query(database,sql_query)\n",
        "    print(f\"Question {i}: {question}\\n\")\n",
        "    print(\"Generated SQL Query:\\n\")\n",
        "    print(sql_query + \"\\n\")\n",
        "    print(\"Fetched result from database:\\n\")\n",
        "    print(result)\n",
        "    print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLjZLp6QNO8",
        "outputId": "e9720841-d455-4ea5-b363-0f4c85974108"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Show me the top 5 highest-paid employees.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT * \n",
            "FROM employees\n",
            "ORDER BY salary DESC\n",
            "LIMIT 5;\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "[(21, 'Alex', 'Johnson', 50, 'Management', 'CEO', 200000.0, '01/01/2010', 22), (2, 'Jane', 'Doe', 34, 'Engineering', 'Developer', 95000.0, '23/05/2016', 6), (6, 'David', 'Jones', 38, 'Engineering', 'Manager', 95000.0, '17/09/2019', 1), (10, 'Robert', 'Rodriguez', 41, 'Engineering', 'QA', 95000.0, '23/05/2016', 6), (14, 'Richard', 'Gonzalez', 42, 'Engineering', 'DevOps', 95000.0, '17/09/2019', 6)]\n",
            "==================================================\n",
            "\n",
            "Question 2: Who is the youngest employee in the Engineering department?\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT employee_name\n",
            "FROM employees\n",
            "WHERE department = 'Engineering'\n",
            "ORDER BY age ASC\n",
            "LIMIT 1;\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "no such column: employee_name\n",
            "==================================================\n",
            "\n",
            "Question 3: Find all employees who were hired in the year 2019.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT * \n",
            "FROM employees\n",
            "WHERE YEAR(hire_date) = 2019;\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "no such column: hire_date\n",
            "==================================================\n",
            "\n",
            "Question 4: Show the names of employees whose salary is above the average salary in their department.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT name\n",
            "FROM employees\n",
            "WHERE salary > (\n",
            "    SELECT AVG(salary)\n",
            "    FROM employees\n",
            "    WHERE department_id = employees.department_id\n",
            ")\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "no such column: name\n",
            "==================================================\n",
            "\n",
            "Question 5: Display the names of employees whose first and last names start with the same letter.\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT name\n",
            "FROM employees\n",
            "WHERE SUBSTRING(name, 1, 1) = SUBSTRING(name, INSTR(name, ' ') + 1, 1);\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "no such column: name\n",
            "==================================================\n",
            "\n",
            "Question 6: Find the employee with the highest salary in each department\n",
            "\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT department, MAX(salary) AS highest_salary\n",
            "FROM employees\n",
            "GROUP BY department;\n",
            "\n",
            "Fetched result from database:\n",
            "\n",
            "[('Engineering', 95000.0), ('HR', 70000.0), ('Management', 200000.0), ('Marketing', 80000.0), ('Sales', 85000.0)]\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}